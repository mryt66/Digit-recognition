{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ace1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "train_data = MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    \n",
    "    'train': DataLoader(train_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1),\n",
    "    'test': DataLoader(test_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f3f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class CNN(nn.Module): # CNN to Convolutional Neural Network Chodzi o to, że robimy 2 typy warstw conv i fc(liniowa)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() #wywołanie konstruktora dziedziczącego \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  #2D warstwa z 1 -> 10 \"kółeczek\"\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop= nn.Dropout2d() #warstwa regulująca co wywala niektóre neurony, żeby niepotrzebnie je trenować\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10) #na końcu 10 bo tyle jest cyfr\n",
    "        \n",
    "    def forward(self, x): #instrukcja przejścia dalej\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x = x.view(-1, 320) #20x4x4\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6362a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcin\\AppData\\Local\\Temp\\ipykernel_18304\\605878062.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t 2.300617\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t 1.848403\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t 1.722433\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t 1.648449\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t 1.643362\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t 1.579871\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy 9379/10000 (94%\n",
      ")\n",
      "10000\n",
      "Train Epoch: 2 [0/60000 (0%)]\t 1.582878\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t 1.590081\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t 1.672150\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t 1.527065\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t 1.533744\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t 1.534594\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9584/10000 (96%\n",
      ")\n",
      "10000\n",
      "Train Epoch: 3 [0/60000 (0%)]\t 1.602865\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t 1.582344\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t 1.520034\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t 1.550703\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t 1.535447\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t 1.557585\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9602/10000 (96%\n",
      ")\n",
      "10000\n",
      "Train Epoch: 4 [0/60000 (0%)]\t 1.567883\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t 1.527228\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t 1.534502\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t 1.577739\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t 1.550343\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t 1.551884\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy 9663/10000 (97%\n",
      ")\n",
      "10000\n",
      "Train Epoch: 5 [0/60000 (0%)]\t 1.586030\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t 1.612299\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t 1.520269\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t 1.552945\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t 1.544202\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t 1.549424\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9688/10000 (97%\n",
      ")\n",
      "10000\n",
      "Train Epoch: 6 [0/60000 (0%)]\t 1.569304\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t 1.500852\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t 1.528757\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t 1.553096\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t 1.556348\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t 1.500407\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9730/10000 (97%\n",
      ")\n",
      "10000\n",
      "Train Epoch: 7 [0/60000 (0%)]\t 1.512032\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t 1.534937\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t 1.525780\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t 1.518256\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t 1.544211\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t 1.527417\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9746/10000 (97%\n",
      ")\n",
      "10000\n",
      "Train Epoch: 8 [0/60000 (0%)]\t 1.546481\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t 1.501254\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t 1.500625\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t 1.522756\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t 1.538795\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t 1.535513\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy 9760/10000 (98%\n",
      ")\n",
      "10000\n",
      "Train Epoch: 9 [0/60000 (0%)]\t 1.521922\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t 1.511910\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t 1.525840\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t 1.533225\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t 1.518525\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t 1.544130\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy 9763/10000 (98%\n",
      ")\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target) #kalkulacja strat\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t {loss.item():.6f}')\n",
    "    \n",
    "def test():\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%\\n)')\n",
    "    print(f'{len(loaders[\"test\"].dataset)}')\n",
    "\n",
    "for epoch in range(1,10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28dbd669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcin\\AppData\\Local\\Temp\\ipykernel_18304\\605878062.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[3256]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f'Prediction: {prediction}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb86a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
